{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team id: 3<br>\n",
    "Div - C<br>\n",
    "Semester - 5th<br>\n",
    "School Of Computer Science and Engineering\n",
    "\n",
    "**5DMACP06 Richter's Predictor Modelling Earthquake**\n",
    "\n",
    "Problem Statement :-\n",
    "Based on aspects of building location and construction, the goal is to predict the level of damage to buildings\n",
    "caused by the 2015 Gorkha earthquake in Nepal.\n",
    "\n",
    "Team Leader:<br>\n",
    "Nitin Verma     Roll No: 148, USN: 01FE17BCS125\n",
    "\n",
    "Team Members:<br>\n",
    "Puneet Gupta    Roll No: 166, USN: 01FE17BCS144<br>\n",
    "Rahetul Asquin  Roll No: 170, USN: 01FE17BCS148<br>\n",
    "Ritbik Bharti   Roll No: 179, USN: 01FE17BCS158<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the datasets\n",
    "\n",
    "train_values = pd.read_csv('Data/train_values.csv')\n",
    "train_labels = pd.read_csv('Data/train_labels.csv')\n",
    "test_values = pd.read_csv('Data/test_values.csv')\n",
    "submission = pd.read_csv('Data/submission_format.csv')\n",
    "train_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the first 5 tuples of training labels\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the first 5 tuples of testing values\n",
    "\n",
    "test_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the first 5 tuples of submission format\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Getting a concise summary of the training data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:-**\n",
    "- 31 numerical attributes\n",
    "- 8 categorical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Checking for any missing values **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns With Missing Values as a List\n",
    "\n",
    "def getColumnsWithMissingValuesList(df):\n",
    "    return [col for col in df.columns if df[col].isnull().any()] \n",
    "\n",
    "getColumnsWithMissingValuesList(train_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "- There is no any missing data in the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Checking for percentage of missing values of each attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Missing Values Info\n",
    "\n",
    "def missingValuesInfo(df):\n",
    "    total = df.isnull().sum().sort_values(ascending = False)\n",
    "    percent = round(df.isnull().sum().sort_values(ascending = False)/len(df)*100, 2)\n",
    "    temp = pd.concat([total, percent], axis = 1,keys= ['Total', 'Percentage'])\n",
    "    return temp.loc[(temp['Total'] > 0)]\n",
    "\n",
    "missingValuesInfo(train_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "- There is no any missing data in the training data\n",
    "- Therefore nill percentages of missing values of each attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Checking for any NaN values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "- There is no any NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns of object Data Type (Categorical Columns) as a List\n",
    "\n",
    "def getObjectColumnsList(df):\n",
    "    return [cname for cname in df.columns if df[cname].dtype == \"object\"]\n",
    "\n",
    "cat_cols = getObjectColumnsList(train_values)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns that Contain Numeric Values as a List\n",
    "\n",
    "def getNumericColumnsList(df):\n",
    "    return [cname for cname in df.columns if df[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "num_cols = getNumericColumnsList(train_values)\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining labels data in training data\n",
    "train_values['damage_grade'] = pd.Series(train_labels['damage_grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corelation between all attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_values.corr(method ='pearson')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corelation between dependent and independent attribute**\n",
    "- The Pearson correlation coefficient (named for Karl Pearson) can be used to summarize the strength of the linear relationship between two data samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_values.corr(method ='pearson')\n",
    "df['damage_grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To view some basic statistical details like percentile, mean, std etc. of the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:-**\n",
    "* area_percentage\n",
    "    - Min is 1 and max is 100, thats a big difference in percentages\n",
    "* age\n",
    "    - Mean age is 26 wheres some values are near to 1000\n",
    "    - Max values are less than 100\n",
    "* height_percentage\n",
    "    - Max is 32 and mean is 5, hence large deviation of max value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the target variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'damage_grade', data = train_labels)\n",
    "plt.title('Number of Buildings with Each Damage Grade');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1: \",sum(train_values.damage_grade==1))\n",
    "print(\"2: \",sum(train_values.damage_grade==2))\n",
    "print(\"3: \",sum(train_values.damage_grade==3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:-**\n",
    "- Most houses have damage grade 2\n",
    "- Damage grade 1 has less number of houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing numerical attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['geo_level_1_id',\n",
    " 'geo_level_2_id',\n",
    " 'geo_level_3_id',\n",
    " 'count_floors_pre_eq',\n",
    " 'age',\n",
    " 'area_percentage',\n",
    " 'height_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values[num_col].hist( figsize=(20,10), layout=(3, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:-**\n",
    "- The age of houses is less than 100, except few being around 1000\n",
    "- The height percentage is more in the range 2 to 8\n",
    "- The area_percentage is more dense in the range 0-19 , very few are around 40\n",
    "- The count_floors_per_sq is amlost in the range 1-4, very few are > 5\n",
    "- Geo_level_2_id and Geo_level_3_id are symmetrically distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing Categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for variable, subplot in zip(cat_cols, ax.flatten()):\n",
    "    sns.countplot(train_values[variable], ax=subplot)\n",
    "    for label in subplot.get_xticklabels():\n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:-**\n",
    "- We got to know which categorical attribute is more significant after one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking skewness of Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_values.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:-**\n",
    "- If the value is near to zero then less skewed\n",
    "- Age is a skewed attribute\n",
    "- Features with external facilities like police, school etc are highly skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Analysing the age attribute **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_values.age, color='red')\n",
    "plt.xlabel('Age')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:-**\n",
    "- Most of the age values is < 100\n",
    "- Some values is near to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
